{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy torch torchvision torchaudio scikit-image matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import torch.utils.data as data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "data_directory = os.getenv(\"DATASET1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663\n",
      "662\n"
     ]
    }
   ],
   "source": [
    "all_files = os.listdir(data_directory)\n",
    "print(len(all_files))\n",
    "all_files = [f for f in all_files if f.endswith('.png') and f[-5] in ['0', '1']]\n",
    "print(len(all_files))\n",
    "\n",
    "for i in all_files:\n",
    "    if i[-5] not in ['0', '1']:\n",
    "        print(i)\n",
    "    # print(i[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')  \n",
    "elif torch.xpu.is_available():\n",
    "    device = torch.device(\"xpu\")\n",
    "    print(\"Using Intel GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using NVIDIA GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how we want to prepare our images for the neural network\n",
    "# This converts the image to a format the network can understand\n",
    "data_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "# This function loads and prepares each image for our neural network\n",
    "def CNNloader(data_root, filename):\n",
    "    # Load the image and resize it to 224x224 pixels\n",
    "    filename_actual = data_root + '/' + filename\n",
    "    data_old = io.imread(filename_actual)\n",
    "    data_old = resize(data_old, (224, 224))\n",
    "    data_old = np.array(data_old, dtype=np.float32)\n",
    "    \n",
    "    # If the image is black and white, convert it to a color image\n",
    "    # (Our neural network expects color images)\n",
    "    if len(data_old.shape) <= 2:\n",
    "        data_new = np.zeros(data_old.shape + (3,))\n",
    "        data_new[:,:,0] = data_new[:,:,1] = data_new[:,:,2] = np.array(data_old)\n",
    "        data_old = np.array(data_new, dtype=np.float32)\n",
    "    \n",
    "    # Apply our predefined transformations\n",
    "    data_old = data_transforms(np.array(data_old))\n",
    "    return data_old\n",
    "\n",
    "# This class helps organize our data and labels\n",
    "class CNNDataLayer(data.Dataset):\n",
    "    def __init__(self, data_root, filenames, loader):\n",
    "        self.data_root = data_root\n",
    "        self.filenames = filenames\n",
    "        self.loader = loader\n",
    "\n",
    "    # This tells the computer how to get each image and its label\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filenames[index]\n",
    "        # We assume the label (0 or 1) is the second-to-last character in the filename\n",
    "        target = [int(filename[-5])]\n",
    "        target = torch.from_numpy(np.array(target))\n",
    "        data = self.loader(self.data_root, filename)\n",
    "        return data, target\n",
    "\n",
    "    # This tells the computer how many images we have\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(662,)\n",
      "(463,) (199,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaanjijoe/MACHINE_LEARNING_ENVIRONMENT/env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shaanjijoe/MACHINE_LEARNING_ENVIRONMENT/env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# print(\"Using device:\", device)\n",
    "# Get a list of all our image files and shuffle them randomly\n",
    "all_files = np.array(all_files)\n",
    "print(all_files.shape)\n",
    "np.random.shuffle(all_files)\n",
    "\n",
    "# Split our data: 70% for training, 30% for testing\n",
    "# train_files = all_files[:round(0.7*all_files.shape[0])]\n",
    "train_files = all_files[:round(0.70*all_files.shape[0])]\n",
    "test_files = all_files[round(0.70*all_files.shape[0]):]\n",
    "print(train_files.shape, test_files.shape)\n",
    "\n",
    "# Create our datasets using the custom class we defined earlier\n",
    "data_sets_train = CNNDataLayer(data_root=data_directory, filenames=train_files, loader=CNNloader)\n",
    "data_sets_test = CNNDataLayer(data_root=data_directory, filenames=test_files, loader=CNNloader)\n",
    "\n",
    "# Create data loaders that will help feed data to our neural network in batches\n",
    "data_loaders_train = data.DataLoader(data_sets_train, batch_size=8, shuffle=True, num_workers=0)\n",
    "data_loaders_test = data.DataLoader(data_sets_test, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "# Load a pre-trained neural network (VGG16) that's good at understanding images\n",
    "model_to_train = models.vgg16(pretrained=True)\n",
    "# model_to_train.load_state_dict(torch.load(\"./vgg16-397923af.pth\"))\n",
    "\n",
    "# We don't want to retrain the whole network, so we \"freeze\" most of it\n",
    "for param in model_to_train.features.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "# Modify the last part of the network to focus on our specific task (finding tuberculosis)\n",
    "num_features = model_to_train.classifier[6].in_features\n",
    "features = list(model_to_train.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(num_features, 1), nn.Sigmoid()])\n",
    "model_to_train.classifier = nn.Sequential(*features)\n",
    "\n",
    "# Alternatively, we could use a custom-made neural network\n",
    "# from own_cnn_model import SimpleCNN\n",
    "# model_to_train = SimpleCNN()\n",
    "model_to_train = model_to_train.to(device)\n",
    "\n",
    "# Set up the \"loss function\" (how the network measures its mistakes)\n",
    "# and the \"optimizer\" (how the network learns from its mistakes)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_ft = optim.SGD(model_to_train.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 1\n",
      "Epoch 1 - Test Metrics:\n",
      "Accuracy: 0.8693\n",
      "Precision: 0.9634\n",
      "Recall: 0.7745\n",
      "F1 Score: 0.8587\n",
      "Epoch is 2\n",
      "Epoch 2 - Test Metrics:\n",
      "Accuracy: 0.8492\n",
      "Precision: 0.8913\n",
      "Recall: 0.8039\n",
      "F1 Score: 0.8454\n",
      "Epoch is 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model_to_train\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 12\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_now\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_now\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Move data to GPU if available\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_now\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_now\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_now\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_now\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make predictions\u001b[39;49;00m\n",
      "File \u001b[0;32m~/MACHINE_LEARNING_ENVIRONMENT/env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/MACHINE_LEARNING_ENVIRONMENT/env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/MACHINE_LEARNING_ENVIRONMENT/env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[20], line 38\u001b[0m, in \u001b[0;36mCNNDataLayer.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     36\u001b[0m target \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(filename[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m])]\n\u001b[1;32m     37\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(target))\n\u001b[0;32m---> 38\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, target\n",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m, in \u001b[0;36mCNNloader\u001b[0;34m(data_root, filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m filename_actual \u001b[38;5;241m=\u001b[39m data_root \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename\n\u001b[1;32m     10\u001b[0m data_old \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(filename_actual)\n\u001b[0;32m---> 11\u001b[0m data_old \u001b[38;5;241m=\u001b[39m \u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_old\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m data_old \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data_old, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# If the image is black and white, convert it to a color image\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# (Our neural network expects color images)\u001b[39;00m\n",
      "File \u001b[0;32m~/MACHINE_LEARNING_ENVIRONMENT/env/lib/python3.12/site-packages/skimage/transform/_warps.py:196\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((anti_aliasing_sigma \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (factors \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    192\u001b[0m             warn(\n\u001b[1;32m    193\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-aliasing standard deviation greater than zero but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot down-sampling along all axes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m             )\n\u001b[0;32m--> 196\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manti_aliasing_sigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndi_mode\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m image\n",
      "File \u001b[0;32m~/MACHINE_LEARNING_ENVIRONMENT/env/lib/python3.12/site-packages/scipy/ndimage/_filters.py:385\u001b[0m, in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate, radius, axes)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, sigma, order, mode, radius \u001b[38;5;129;01min\u001b[39;00m axes:\n\u001b[0;32m--> 385\u001b[0m         \u001b[43mgaussian_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/MACHINE_LEARNING_ENVIRONMENT/env/lib/python3.12/site-packages/scipy/ndimage/_filters.py:283\u001b[0m, in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate, radius)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# Since we are calling correlate, not convolve, revert the kernel\u001b[39;00m\n\u001b[1;32m    282\u001b[0m weights \u001b[38;5;241m=\u001b[39m _gaussian_kernel1d(sigma, order, lw)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MACHINE_LEARNING_ENVIRONMENT/env/lib/python3.12/site-packages/scipy/ndimage/_filters.py:140\u001b[0m, in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid origin; origin must satisfy \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-(len(weights) // 2) <= origin <= \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(len(weights)-1) // 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    139\u001b[0m mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[0;32m--> 140\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                      \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start the training process\n",
    "num_epochs = 5  # We'll train for 100 rounds\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print('Epoch is ' + str(epoch))\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    total_misclassified_train = total_count_train = 0\n",
    "    total_misclassified_test = total_count_test = 0\n",
    "    \n",
    "    # Training phase\n",
    "    model_to_train.train()\n",
    "    for batch_idx, (data_now, target_now) in enumerate(data_loaders_train):\n",
    "        # Move data to GPU if available\n",
    "        data_now, target_now = data_now.to(device), target_now.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        target_output_model = model_to_train(data_now)\n",
    "        target_now = target_now.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        # Calculate loss (how wrong the predictions were)\n",
    "        target_loss = criterion(target_output_model, target_now)\n",
    "        \n",
    "        # Calculate how many predictions were wrong\n",
    "        misclassified_temp = target_output_model[target_now == 1]\n",
    "        total_misclassified_train += (misclassified_temp < 0.5).sum().item()\n",
    "        misclassified_temp = target_output_model[target_now == 0]\n",
    "        total_misclassified_train += (misclassified_temp >= 0.5).sum().item()\n",
    "        total_count_train += data_now.shape[0]\n",
    "        \n",
    "        # Learn from the mistakes (backpropagation)\n",
    "        optimizer_ft.zero_grad()\n",
    "        target_loss.backward()\n",
    "        optimizer_ft.step()\n",
    "    \n",
    "    # Testing phase (similar to training, but we don't learn from these)\n",
    "    model_to_train.eval()\n",
    "\n",
    "    # Store all predictions and true labels for metrics\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data_now, target_now) in enumerate(data_loaders_test):\n",
    "            data_now, target_now = data_now.to(device), target_now.to(device)\n",
    "            target_output_model = model_to_train(data_now)\n",
    "            \n",
    "            # Convert outputs to binary predictions\n",
    "            predicted_labels = (target_output_model >= 0.5).float()\n",
    "            all_predictions.extend(predicted_labels.cpu().numpy())\n",
    "            all_targets.extend(target_now.cpu().numpy())\n",
    "            \n",
    "            # Calculate how many predictions were wrong\n",
    "            misclassified_temp = target_output_model[target_now == 1]\n",
    "            total_misclassified_test += (misclassified_temp < 0.5).sum().item()\n",
    "            misclassified_temp = target_output_model[target_now == 0]\n",
    "            total_misclassified_test += (misclassified_temp >= 0.5).sum().item()\n",
    "            total_count_test += data_now.shape[0]\n",
    "    \n",
    "    # Convert lists to numpy arrays for metric calculations\n",
    "    all_predictions = np.array(all_predictions).flatten()\n",
    "    all_targets = np.array(all_targets).flatten()\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = np.mean(all_predictions == all_targets)\n",
    "    precision = precision_score(all_targets, all_predictions)\n",
    "    recall = recall_score(all_targets, all_predictions)\n",
    "    f1 = f1_score(all_targets, all_predictions)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(f'Epoch {epoch} - Test Metrics:')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    \n",
    "    # Save our progress (the network's current state)\n",
    "    snapshot_path = './snapshots_trial'\n",
    "    os.makedirs(snapshot_path, exist_ok=True)\n",
    "    snapshot_name = f'epoch-{epoch}-trainerror-{total_misclassified_train/total_count_train:.4f}-testerror-{total_misclassified_test/total_count_test:.4f}.pth'\n",
    "    torch.save(model_to_train.state_dict(), os.path.join(snapshot_path, snapshot_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
