{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy torch torchvision torchaudio scikit-image matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import torch.utils.data as data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\honey\\AppData\\Local\\Temp\\ipykernel_21948\\3694138203.py:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  data_directory = 'C:\\Programming\\python\\Tuberculosis_detection_using_deep_learning_and_CNN\\Tuberculosis_dataset\\ChinaSet_AllFiles\\ChinaSet_AllFiles\\CXR_png'\n"
     ]
    }
   ],
   "source": [
    "data_directory = 'C:\\Programming\\python\\Tuberculosis_detection_using_deep_learning_and_CNN\\Tuberculosis_dataset\\ChinaSet_AllFiles\\ChinaSet_AllFiles\\CXR_png'\n",
    "# print(data_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\python\\Tuberculosis_detection_using_deep_learning_and_CNN\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Programming\\python\\Tuberculosis_detection_using_deep_learning_and_CNN\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 1\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 205. MiB for an array with shape (2989, 2992, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[0;32m     97\u001b[0m model_to_train\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 98\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_now\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_now\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Move data to GPU if available\u001b[39;49;00m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_now\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_now\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_now\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_now\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make predictions\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Programming\\python\\Tuberculosis_detection_using_deep_learning_and_CNN\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Programming\\python\\Tuberculosis_detection_using_deep_learning_and_CNN\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Programming\\python\\Tuberculosis_detection_using_deep_learning_and_CNN\\env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 37\u001b[0m, in \u001b[0;36mCNNDataLayer.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     35\u001b[0m target \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(filename[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m])]\n\u001b[0;32m     36\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(target))\n\u001b[1;32m---> 37\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, target\n",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m, in \u001b[0;36mCNNloader\u001b[1;34m(data_root, filename)\u001b[0m\n\u001b[0;32m      8\u001b[0m filename_actual \u001b[38;5;241m=\u001b[39m data_root \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename\n\u001b[0;32m      9\u001b[0m data_old \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(filename_actual)\n\u001b[1;32m---> 10\u001b[0m data_old \u001b[38;5;241m=\u001b[39m \u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_old\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m data_old \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data_old, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# If the image is black and white, convert it to a color image\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# (Our neural network expects color images)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programming\\python\\Tuberculosis_detection_using_deep_learning_and_CNN\\env\\Lib\\site-packages\\skimage\\transform\\_warps.py:196\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((anti_aliasing_sigma \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (factors \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    192\u001b[0m             warn(\n\u001b[0;32m    193\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-aliasing standard deviation greater than zero but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot down-sampling along all axes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m             )\n\u001b[1;32m--> 196\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manti_aliasing_sigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndi_mode\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m image\n",
      "File \u001b[1;32mc:\\Programming\\python\\Tuberculosis_detection_using_deep_learning_and_CNN\\env\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:373\u001b[0m, in \u001b[0;36mgaussian_filter\u001b[1;34m(input, sigma, order, output, mode, cval, truncate, radius, axes)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Multidimensional Gaussian filter.\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m>>> plt.show()\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m--> 373\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_ni_support\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m axes \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_check_axes(axes, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m    376\u001b[0m num_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axes)\n",
      "File \u001b[1;32mc:\\Programming\\python\\Tuberculosis_detection_using_deep_learning_and_CNN\\env\\Lib\\site-packages\\scipy\\ndimage\\_ni_support.py:79\u001b[0m, in \u001b[0;36m_get_output\u001b[1;34m(output, input, shape, complex_output)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m complex_output:\n\u001b[1;32m---> 79\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m         complex_type \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpromote_types(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mcomplex64)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 205. MiB for an array with shape (2989, 2992, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "# Define how we want to prepare our images for the neural network\n",
    "# This converts the image to a format the network can understand\n",
    "data_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# This function loads and prepares each image for our neural network\n",
    "def CNNloader(data_root, filename):\n",
    "    # Load the image and resize it to 224x224 pixels\n",
    "    filename_actual = data_root + '/' + filename\n",
    "    data_old = io.imread(filename_actual)\n",
    "    data_old = resize(data_old, (224, 224))\n",
    "    data_old = np.array(data_old, dtype=np.float32)\n",
    "    \n",
    "    # If the image is black and white, convert it to a color image\n",
    "    # (Our neural network expects color images)\n",
    "    if len(data_old.shape) <= 2:\n",
    "        data_new = np.zeros(data_old.shape + (3,))\n",
    "        data_new[:,:,0] = data_new[:,:,1] = data_new[:,:,2] = np.array(data_old)\n",
    "        data_old = np.array(data_new, dtype=np.float32)\n",
    "    \n",
    "    # Apply our predefined transformations\n",
    "    data_old = data_transforms(np.array(data_old))\n",
    "    return data_old\n",
    "\n",
    "# This class helps organize our data and labels\n",
    "class CNNDataLayer(data.Dataset):\n",
    "    def __init__(self, data_root, filenames, loader):\n",
    "        self.data_root = data_root\n",
    "        self.filenames = filenames\n",
    "        self.loader = loader\n",
    "\n",
    "    # This tells the computer how to get each image and its label\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filenames[index]\n",
    "        # We assume the label (0 or 1) is the second-to-last character in the filename\n",
    "        target = [int(filename[-5])]\n",
    "        target = torch.from_numpy(np.array(target))\n",
    "        data = self.loader(self.data_root, filename)\n",
    "        return data, target\n",
    "\n",
    "    # This tells the computer how many images we have\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "# Check if we can use a GPU (which is faster) or if we need to use a CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Get a list of all our image files and shuffle them randomly\n",
    "all_files = np.array(os.listdir(data_directory))\n",
    "np.random.shuffle(all_files)\n",
    "\n",
    "# Split our data: 70% for training, 30% for testing\n",
    "train_files = all_files[:round(0.7*all_files.shape[0])]\n",
    "test_files = all_files[round(0.7*all_files.shape[0]):]\n",
    "\n",
    "# Create our datasets using the custom class we defined earlier\n",
    "data_sets_train = CNNDataLayer(data_root=data_directory, filenames=train_files, loader=CNNloader)\n",
    "data_sets_test = CNNDataLayer(data_root=data_directory, filenames=test_files, loader=CNNloader)\n",
    "\n",
    "# Create data loaders that will help feed data to our neural network in batches\n",
    "data_loaders_train = data.DataLoader(data_sets_train, batch_size=8, shuffle=True, num_workers=0)\n",
    "data_loaders_test = data.DataLoader(data_sets_test, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "# Load a pre-trained neural network (VGG16) that's good at understanding images\n",
    "model_to_train = models.vgg16(pretrained=True)\n",
    "# model_to_train.load_state_dict(torch.load(\"./vgg16-397923af.pth\"))\n",
    "\n",
    "# We don't want to retrain the whole network, so we \"freeze\" most of it\n",
    "for param in model_to_train.features.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "# Modify the last part of the network to focus on our specific task (finding tuberculosis)\n",
    "num_features = model_to_train.classifier[6].in_features\n",
    "features = list(model_to_train.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(num_features, 1), nn.Sigmoid()])\n",
    "model_to_train.classifier = nn.Sequential(*features)\n",
    "\n",
    "# Alternatively, we could use a custom-made neural network\n",
    "# from own_cnn_model import SimpleCNN\n",
    "# model_to_train = SimpleCNN()\n",
    "model_to_train = model_to_train.to(device)\n",
    "\n",
    "# Set up the \"loss function\" (how the network measures its mistakes)\n",
    "# and the \"optimizer\" (how the network learns from its mistakes)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_ft = optim.SGD(model_to_train.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Start the training process\n",
    "num_epochs = 100  # We'll train for 100 rounds\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print('Epoch is ' + str(epoch))\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    total_misclassified_train = total_count_train = 0\n",
    "    total_misclassified_test = total_count_test = 0\n",
    "    \n",
    "    # Training phase\n",
    "    model_to_train.train()\n",
    "    for batch_idx, (data_now, target_now) in enumerate(data_loaders_train):\n",
    "        # Move data to GPU if available\n",
    "        data_now, target_now = data_now.to(device), target_now.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        target_output_model = model_to_train(data_now)\n",
    "        target_now = target_now.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        # Calculate loss (how wrong the predictions were)\n",
    "        target_loss = criterion(target_output_model, target_now)\n",
    "        \n",
    "        # Calculate how many predictions were wrong\n",
    "        misclassified_temp = target_output_model[target_now == 1]\n",
    "        total_misclassified_train += (misclassified_temp < 0.5).sum().item()\n",
    "        misclassified_temp = target_output_model[target_now == 0]\n",
    "        total_misclassified_train += (misclassified_temp >= 0.5).sum().item()\n",
    "        total_count_train += data_now.shape[0]\n",
    "        \n",
    "        # Learn from the mistakes (backpropagation)\n",
    "        optimizer_ft.zero_grad()\n",
    "        target_loss.backward()\n",
    "        optimizer_ft.step()\n",
    "    \n",
    "    # Testing phase (similar to training, but we don't learn from these)\n",
    "    model_to_train.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data_now, target_now) in enumerate(data_loaders_test):\n",
    "            data_now, target_now = data_now.to(device), target_now.to(device)\n",
    "            target_output_model = model_to_train(data_now)\n",
    "            \n",
    "            # Calculate how many predictions were wrong\n",
    "            misclassified_temp = target_output_model[target_now == 1]\n",
    "            total_misclassified_test += (misclassified_temp < 0.5).sum().item()\n",
    "            misclassified_temp = target_output_model[target_now == 0]\n",
    "            total_misclassified_test += (misclassified_temp >= 0.5).sum().item()\n",
    "            total_count_test += data_now.shape[0]\n",
    "    \n",
    "    # Save our progress (the network's current state)\n",
    "    snapshot_path = './snapshots_trial'\n",
    "    os.makedirs(snapshot_path, exist_ok=True)\n",
    "    snapshot_name = f'epoch-{epoch}-trainerror-{total_misclassified_train/total_count_train:.4f}-testerror-{total_misclassified_test/total_count_test:.4f}.pth'\n",
    "    torch.save(model_to_train.state_dict(), os.path.join(snapshot_path, snapshot_name))\n",
    "\n",
    "# Example of how to load a saved model for later use\n",
    "model_loaded = torch.load(\"./snapshots/epoch-5-trainerror-0.1447-testerror-0.1558.pth\", map_location=lambda storage, loc: storage)\n",
    "model_to_train.load_state_dict(model_loaded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
